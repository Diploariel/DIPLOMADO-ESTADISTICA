# -*- coding: utf-8 -*-
"""AED_PROY3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jkcsel9gQGkGNFo-OrkqycIyEXxeFiWQ

# **ANALISIS EXPLORATORIO DE DATOS Y CREACION DE MODELO DE CLASIFICACION DEL IMPACTO SOBRE (INCLUSION DIGITAL EN LAS ESCUELAS PUBLICAS DE BOLIVIA)**

## **ENTENDIMIENTO DE LOS DATOS**

### **RECOLECCION DE DATOS**

**PASO 1: CONFIGURACION INICIAL**
"""

#Importa las librerias necesarias
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

# Acceder al archivo en tu unidad de Google Drive
ruta_archivo = '/content/drive/MyDrive/profesores_final.xlsx'

#creaion del DataFrame
df = pd.read_excel(ruta_archivo)

"""**PASO 2: EXPLORACION INICIAL DE DATOS**"""

#Muestra los primeros registros del DataFrame
df.head()

def imprimir_columnas_por_tipo(df, tipo_dato):
    columnas_seleccionadas = df.select_dtypes(include=[tipo_dato]).columns
    for columna in columnas_seleccionadas:
        print(columna)

# Para imprimir las columnas de tipo 'object'
print("Columnas de tipo 'object':")
imprimir_columnas_por_tipo(df, 'object')

# Para imprimir las columnas de tipo 'int'
print("\nColumnas de tipo 'int':")
imprimir_columnas_por_tipo(df, 'int')

#Obtencion de informacion sobre el DataFrame
df.info()

#Obtencion del tamaño del DataFrame
df.shape

df.dtypes

"""**PASO 3: ESTADISTICAS DESCRIPTIVAS**"""

#Para obtener estadistica descritiva basicas
df.describe()

"""**PASO 4: VISUALIZACIONES**"""

#Grafico de Histograma para la variable Edad
plt.hist(df['Edad'], bins=20, color='#4169E1')
plt.ylabel('Frecuencia')
plt.title('Edad')
plt.show()

#Grafico de histograma para la variable Años de experiencia
plt.hist(df['Años de experiencia'], bins=20, color='#4169E1')
plt.ylabel('Frecuencia')
plt.title('Años de experiencia')
plt.show()

#Grafico de varaible Años en el Colegio
plt.hist(df['Años en el Colegio'], bins=20, color='#4169E1')
plt.ylabel('Frecuencia')
plt.title('Años de antiguedad')
plt.show()

#Grafico de varaible cantidad de computadoras
plt.hist(df['Cantidad de computadoras'], bins=20, color='#4169E1')
plt.ylabel('Frecuencia')
plt.title('Cantidad de computadoras que tiene un maestro')
plt.show()

#Grafico de varaible
plt.hist(df['Cantidad de Tablets'], bins=20, color='#4169E1')
plt.ylabel('Frecuencia')
plt.title('Cantidad de Tablets por profesor')
plt.show()

#Grafico de varaible
plt.hist(df['Dias en la semana usando internet'], bins=20, color='#4169E1')
plt.ylabel('Frecuencia')
plt.title('Dias por semana usando internet')
plt.show()

ax = sns.countplot(data=df, x='Departamento')
plt.xlabel('Departamento')
plt.ylabel('Frecuencia')
plt.title('Gráfico de Barras de Departameto')
plt.xticks(rotation=45)
total = float(len(df['Departamento']))
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{(height/total)*100:.1f}%', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

variables = ['Normalista','Tecnico','Licenciatura','Especialidad','Mestria']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Nivel Academico')
plt.xticks(rotation=45)
plt.show()

ax = sns.countplot(data=df, x='Area de Materia')
plt.ylabel('Frecuencia')
plt.title('Area de Materia')
plt.xticks(rotation=75)
total = float(len(df['Area de Materia']))
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{(height/total)*100:.1f}%', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

variables = ['Matematica','Tecnica tecnologica','Ciencia Naturales','Geografia','Biologia','Fisica',
             'Quimica','Lenguaje','Lengua extranjera','Ciencias Sociales',
             'Artes Plasticas','Musica','Religion ','Filosofia']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(10, 5))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Materias')
plt.xticks(rotation=75)
plt.show()

variables = ['Facebook','Youtube','Whatsapp','Menssenger','Instagram','Twitter','Telegram','Tiktok']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Redes Sociales')
plt.xticks(rotation=45)
plt.show()

variables = ['Computadora','Tablets','Celular','Celualar inteligente']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Acceso a herramientas')
plt.xticks(rotation=45)
plt.show()

variables = ['Computadora para planillas','Computadora para juegos','Computadora para Estudio',
             'Computadora para Redes Sociales','Computadora para Planificar Clases',
             'Computadora para uso en clases']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Uso de Computadora')
plt.xticks(rotation=75)
plt.show()

variables = ['Celular para llamadas','Celular para juegos','Celular para redes sociales','Celular para internet']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Uso de Celular')
plt.xticks(rotation=75)
plt.show()

variables = ['internet en casa','internet en colegio']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Acceso a Internet')
plt.xticks(rotation=45)
plt.show()

variables = ['Internet para Fines academicos','Internet para descargar','Internet para redes sociales',
             'Internet para busqueda','internet para trabajo','Internet para jugar']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Uso de Internet')
plt.xticks(rotation=75)
plt.show()

variables = ['Uso de Google Academico','Uso de Buscadores','Uso de Google Drive','Uso de correo electronico',
             'Saber 1','Saber 2','Saber 3','Saber 4','Saber 5','Saber 6','Saber 7']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(12, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Uso de conocimientos Informaticos')
plt.xticks(rotation=75)
plt.show()

variables = ['Capacitacion en uso de TIC','Certificado de capacitacion','Conocimiento de metodo TIC',
             'Implemetacion de metodo TIC','Aula en colegio para uso de computadoras','Uso de KUAA alguna vez',
             'Aula para uso de KUAA','Acceso a internet en alguna Aula','Disponibilidad de enseñanza TIC']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(12, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('TIC')
plt.xticks(rotation=75)
plt.show()

ax = sns.countplot(data=df, x='Incorporacion de TIC en aula')
plt.ylabel('Frecuencia')
plt.title('Incorporacion de TIC en aula')
plt.xticks(rotation=45)
total = float(len(df['Incorporacion de TIC en aula']))
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{(height/total)*100:.1f}%', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

variables = ['Preparacion de estudiantes por Videos',
'Preparacion de estudiantes por presentaciones',
'Preparacion de estudiantes mediante textos en linea',
'Presentacion de estudiantes por Textos impresos']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Modo de preparacion de los estudiantes')
plt.xticks(rotation=75)
plt.show()

variables = ['Material de clases de Internet',
'Material de clases de elaboracion propia',
'Material de clases de otras fuentes',
'Material de clases de trabajo compartido']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Elaboracion del Material')
plt.xticks(rotation=75)
plt.show()

ax = sns.countplot(data=df, x='Modalidad de Clases')
plt.ylabel('Frecuencia')
plt.title('Modalidad de Clases')
plt.xticks(rotation=45)
total = float(len(df['Modalidad de Clases']))
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{(height/total)*100:.1f}%', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

variables = ['Requerimiento de Mobiliario',
'Requerimiento de equipo computacional',
'Requerimiento de internet']
# Transponer el DataFrame y reformatear los datos
df_melted = df[variables].melt(var_name='Variable', value_name='Frecuencia')
# Configuración del tamaño de la figura
plt.figure(figsize=(8, 4))
# Crear un gráfico de barras
sns.countplot(data=df_melted, x='Variable', hue='Frecuencia')
plt.legend(title='Frecuencia')
plt.ylabel('Frecuencia')
plt.title('Requerimientos de los Colegios')
plt.xticks(rotation=25)
plt.show()

ax = sns.countplot(data=df, x='Calificacion del proyecto')
plt.ylabel('Frecuencia')
plt.title('Calificacion del proyecto')
plt.xticks(rotation=45)
total = float(len(df['Calificacion del proyecto']))
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{(height/total)*100:.1f}%', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

ax = sns.countplot(data=df, x='Uso de tecnologias mejoro el aprendizaje')
plt.ylabel('Frecuencia')
plt.title('Uso de tecnologias mejoro el aprendizaje')
plt.xticks(rotation=45)
total = float(len(df['Uso de tecnologias mejoro el aprendizaje']))
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{(height/total)*100:.1f}%', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')
plt.show()

"""**PASO 5: MANEJO DE DATOS FALTANTES**"""

df.isnull()

df.isnull().sum()

df.info()

# Crear un mapa de calor para visualizar valores nulos
plt.figure(figsize=(6, 4))

# Utiliza el método heatmap de seaborn
sns.heatmap(df.isnull(), cmap='viridis', cbar=False, yticklabels=False)

plt.title('Mapa de Calor de Valores Nulos')
plt.show()

# Obtener la cantidad de valores nulos por columna
nulos_por_columna = df.isnull().sum()

# Imprimir el nombre de la columna y la cantidad de valores nulos
for columna, cantidad_nulos in nulos_por_columna.items():
    print(f"{columna}:                 {cantidad_nulos} valores nulos")

df['Tipo de computadora'] = df['Tipo de computadora'].fillna('Ninguna')

df['tipo de internet'] = df['tipo de internet'].fillna('Ninguna')

df['lugar de acceso a internet'] = df['lugar de acceso a internet'].fillna('Ninguno')

"""**PASO 6 : MANEJO DE VALORES ATIPICOS**"""

df.shape

# Definir un umbral para identificar valores atípicos (por ejemplo, z-score > 3 o < -3)
umbral = 3

# Iterar a través de las columnas numéricas
for columna in df.select_dtypes(include=[np.number]):
    # Calcular z-scores para la columna actual
    z_scores = (df[columna] - df[columna].mean()) / df[columna].std()

    # Filtrar los datos originales para eliminar los valores atípicos en la columna actual
    df = df[(z_scores < umbral) & (z_scores > -umbral)]

df.shape

"""**PASO 7: ANASLISIS UNIVARIADO Y BIVARAIDO**"""

sns.boxplot(data=df, y='Edad')
plt.ylabel('')
plt.title('Edad')
plt.show()

sns.boxplot(data=df, y='Años de experiencia')
plt.ylabel('')
plt.title('Años de experiencia')
plt.show()

sns.boxplot(data=df, y='Años en el Colegio')
plt.ylabel('')
plt.title('Años en el Colegio')
plt.show()

sns.boxplot(data=df, y='Cantidad de computadoras')
plt.ylabel('')
plt.title('Cantidad de computadoras')
plt.show()

sns.boxplot(data=df, y='Cantidad de Tablets')
plt.ylabel('')
plt.title('Cantidad de Tablets')
plt.show()

sns.boxplot(data=df, y='Dias en la semana usando internet')
plt.ylabel('')
plt.title('Dias en la semana usando internet')
plt.show()

#diagrama de dispersión entre 'edad' y 'años de experiencia'
sns.scatterplot(data=df, x='Edad', y='Años de experiencia', color='#4169E1')
plt.xlabel('edad')
plt.ylabel('años de experiencia')
plt.title('Edad Vs Años de experiencia')
plt.show()

matriz_correlacion = df.corr()
sns.heatmap(matriz_correlacion, annot=True, cmap='coolwarm')
plt.title('Matriz de Correlación')
plt.show()

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Normalista'],df['Tecnico'],df['Licenciatura'],df['Especialidad'],df['Mestria']],
                                 df['Incorporacion de TIC en aula'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab(df['internet en colegio'], df['Incorporacion de TIC en aula'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab(df['Uso de tecnologias mejoro el aprendizaje'], df['Incorporacion de TIC en aula'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Requerimiento de internet'],
                                  df["internet en colegio"]],
                                 df['Aula en colegio para uso de computadoras'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Requerimiento de Mobiliario'],df['Requerimiento de equipo computacional'],
                                  df['Requerimiento de internet'], df['internet en colegio']], df['Aula en colegio para uso de computadoras'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Saber 1'],
df['Incorporacion de TIC en aula']],
df['Disponibilidad de enseñanza TIC'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Saber 3'],
df['Incorporacion de TIC en aula']],
df['Disponibilidad de enseñanza TIC'])
tabla_contingencia

#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Saber 5'],
df['Incorporacion de TIC en aula']],
df['Disponibilidad de enseñanza TIC'])
tabla_contingencia

import pandas as pd
#Correlacion entre varaibles categoricas.
tabla_contingencia = pd.crosstab([df['Uso de Google Academico'],df['Uso de Google Drive'],
df['Incorporacion de TIC en aula']], df['Disponibilidad de enseñanza TIC'])
tabla_contingencia

"""**PASO 8 : SELECCION DE VARAIBLES MAS SOBRESALIENTES**"""

variables_sobresalientes = ['Departamento','internet en colegio', 'Aula en colegio para uso de computadoras',
                            'Modalidad de Clases', 'Incorporacion de TIC en aula',
                            'Uso de tecnologias mejoro el aprendizaje']
df1 = df[variables_sobresalientes].copy()

# Definir una función para evaluar las condiciones y crear la columna 'apto para la inclusion digital'
def evaluar_inclusion_digital(row):
    if (
         row["internet en colegio"] == 'Sí' and
        row['Aula en colegio para uso de computadoras'] == 'Sí' and
        row['Modalidad de Clases'] != "Clases frontales" and
         row["Incorporacion de TIC en aula"] != 'Nunca' and
         row["Uso de tecnologias mejoro el aprendizaje"] == "Sí" #and
         #row["Capacitacion en uso de TIC"] == "Sí"
    ):
        return 'Alto'
    else:
        return 'Bajo'

# Aplicar la función para crear la columna 'apto para la inclusion digital'
df1["impacto de inclusion digital"] = df1.apply(evaluar_inclusion_digital, axis=1)

df1.head()

# prompt: exportar df1 con nombre de tabla minable en formato de excel

df1.to_excel('minable_table.xlsx', index=False)

"""**PASO 9 : EQUIDAD DE VALORES EN CANTIDAD**"""

#mostrar la cantidad de cada valor único en la columna "impacto de inclusion digital"
print(df1["impacto de inclusion digital"].value_counts())

from sklearn.utils import resample

print(df1["impacto de inclusion digital"].value_counts())

# Separar las clases en DataFrames separados
df_class_alto = df1[df1["impacto de inclusion digital"] == 'Alto']
df_class_bajo = df1[df1["impacto de inclusion digital"] == 'Bajo']

# Determinar la cantidad de muestras deseada para equilibrar las clases
target_sample_size = min(len(df_class_alto), len(df_class_bajo))

# Submuestrear cada clase para igualar la cantidad de muestras
df_class_alto_downsampled = resample(df_class_alto, replace=False, n_samples=target_sample_size, random_state=42)
df_class_bajo_downsampled = resample(df_class_bajo, replace=False, n_samples=target_sample_size, random_state=42)

# Combinar las clases balanceadas en un nuevo DataFrame
df2_balanced = pd.concat([df_class_alto_downsampled, df_class_bajo_downsampled])

# Verificar el equilibrio de clases en el nuevo DataFrame
print(df2_balanced["impacto de inclusion digital"].value_counts())

"""**PASO 10: ONE HOT ENCODING**"""

# Crear un diccionario de mapeo de departamentos a valores numéricos
mapeo_departamentos = {
    'Pando': 1,
    'Beni': 2,
    'La Paz': 3,
    'Oruro': 4,
    'Potosí': 5,
    'Cochabamba': 6,
    'Chuquisaca': 7,
    'Tarija': 8,
    'Santa Cruz': 9
}

# Reemplazar los valores en la columna 'Departamento'
df2_balanced['Departamento'] = df2_balanced['Departamento'].replace(mapeo_departamentos)

df2_balanced.shape

# Aplicar One-Hot Encoding a todas las columnas categóricas en df1
df_encoded = pd.get_dummies(df2_balanced)

# Ver el DataFrame con One-Hot Encoding
df_encoded.head()

df_encoded.shape

df_encoded

# Resetear el índice para obtener un índice numérico explícito
df_export = df_encoded.reset_index()

# Alternativamente, si deseas incluir el índice en el archivo CSV
df_export.to_excel("minable_table_encoded.xlsx", index=True)

"""## **MODELAMIENTO, ENTRENAMIENTO Y PRUEBA**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

# Variables predictoras
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre','Incorporacion de TIC en aula_Ocasionalmente',
                'Incorporacion de TIC en aula_Rara vez','Incorporacion de TIC en aula_Siempre',
                'Uso de tecnologias mejoro el aprendizaje_Sí']]

# Variable objetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Dividision de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Creacion del modelo de regresión logística
model = LogisticRegression(max_iter=100)

#Entrenamiento del modelo
model.fit(X_train, y_train)

#Prueba del modelo
y_pred = model.predict(X_test)

# Calculo de las métricas de evaluación
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
y_prob = model.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_prob)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)

# Impresion de las métricas
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("AUC-ROC:", roc_auc)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# Curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head()

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

# Variables predictoras
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre',
                'Incorporacion de TIC en aula_Ocasionalmente','Incorporacion de TIC en aula_Rara vez',
                'Incorporacion de TIC en aula_Siempre','Uso de tecnologias mejoro el aprendizaje_Sí',]]

# Variable onjetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Dividision de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear del Modelo
nb_model = GaussianNB()

#Entrenamiento del modelo
nb_model.fit(X_train, y_train)

#Predicciones en el conjunto de prueba
y_pred_nb = nb_model.predict(X_test)

# Calculo de métricas de evaluación
accuracy_nb = accuracy_score(y_test, y_pred_nb)
precision_nb = precision_score(y_test, y_pred_nb)
recall_nb = recall_score(y_test, y_pred_nb)
f1_nb = f1_score(y_test, y_pred_nb)
y_prob_nb = nb_model.predict_proba(X_test)[:, 1]
roc_auc_nb = roc_auc_score(y_test, y_prob_nb)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_nb)

# Impresion de métricas
print("Accuracy (Naive Bayes):", accuracy_nb)
print("Precision (Naive Bayes):", precision_nb)
print("Recall (Naive Bayes):", recall_nb)
print("F1-score (Naive Bayes):", f1_nb)
print("AUC-ROC (Naive Bayes):", roc_auc_nb)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# Curva ROC
fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, y_prob_nb)
plt.figure()
plt.plot(fpr_nb, tpr_nb, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc_nb)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC (Naive Bayes)')
plt.legend(loc="lower right")
plt.show()

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred_nb})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head()

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

#Variables predictoras
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre','Incorporacion de TIC en aula_Ocasionalmente',
                'Incorporacion de TIC en aula_Rara vez','Incorporacion de TIC en aula_Siempre',
                'Uso de tecnologias mejoro el aprendizaje_Sí',]]

#Varaible objetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Dividision de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Creacion del modelo de k-Nearest Neighbors (k-NN)
knn_model = KNeighborsClassifier(n_neighbors=3)

#Entrenamiento del modelo
knn_model.fit(X_train, y_train)

#Predicciones del conjunto de prueba
y_pred_knn = knn_model.predict(X_test)

# Calculo de métricas de evaluación
accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn)
recall_knn = recall_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_knn)

# Impresion de las métricas
print("Accuracy (k-NN):", accuracy_knn)
print("Precision (k-NN):", precision_knn)
print("Recall (k-NN):", recall_knn)
print("F1-score (k-NN):", f1_knn)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# No se calcula AUC-ROC para k-NN ya que no genera probabilidades directas

# Curva ROC (No aplicable para k-NN)
# k-NN no genera probabilidades directas, por lo que no se puede calcular una curva ROC en este caso.

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred_knn})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head()

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

#Variables predictoras
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre','Incorporacion de TIC en aula_Ocasionalmente',
                'Incorporacion de TIC en aula_Rara vez','Incorporacion de TIC en aula_Siempre',
                'Uso de tecnologias mejoro el aprendizaje_Sí',]]

#Varaible objetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Dividision de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Creacion del modelo SVM con kernel radial (RBF)
svm_model = SVC(kernel='rbf', random_state=42, probability=True)

#Entrenamiento del modelo
svm_model.fit(X_train, y_train)

#Predicciones del conjunto de prueba
y_pred_svm = svm_model.predict(X_test)

# Calculo de métricas de evaluación
accuracy_svm = accuracy_score(y_test, y_pred_svm)
precision_svm = precision_score(y_test, y_pred_svm)
recall_svm = recall_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm)
y_prob_svm = svm_model.predict_proba(X_test)[:, 1]
roc_auc_svm = roc_auc_score(y_test, y_prob_svm)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_svm)

# Impresion de las métricas
print("Accuracy (SVM):", accuracy_svm)
print("Precision (SVM):", precision_svm)
print("Recall (SVM):", recall_svm)
print("F1-score (SVM):", f1_svm)
print("AUC-ROC (SVM):", roc_auc_svm)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# Curva ROC
fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_prob_svm)
plt.figure()
plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc_svm)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC (SVM)')
plt.legend(loc="lower right")
plt.show()

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred_svm})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

#Varaibles predictoras
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre','Incorporacion de TIC en aula_Ocasionalmente',
                'Incorporacion de TIC en aula_Rara vez','Incorporacion de TIC en aula_Siempre',
                'Uso de tecnologias mejoro el aprendizaje_Sí']]

#Varaibles objetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Division de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalamiento de las características para mejorar el rendimiento de la red neuronal
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Creacion de un modelo de red neuronal artificial (ANN)
model = keras.Sequential([
    layers.Input(shape=(X_train_scaled.shape[1],)),  # Capa de entrada con el número de características
    layers.Dense(64, activation='relu'),  # Capa oculta con 64 neuronas y función de activación ReLU
    layers.Dense(1, activation='sigmoid')  # Capa de salida con 1 neurona y función de
                                           #activación sigmoide (para clasificación binaria)
])

# Compilacion del modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenamiento el modelo
model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_split=0.2)

#Predicciones en el conjunto de prueba
y_prob_ann = model.predict(X_test_scaled)
y_pred_ann = (y_prob_ann > 0.5).astype(int)

# Calculo de métricas de evaluación
accuracy_ann = accuracy_score(y_test, y_pred_ann)
precision_ann = precision_score(y_test, y_pred_ann)
recall_ann = recall_score(y_test, y_pred_ann)
f1_ann = f1_score(y_test, y_pred_ann)
roc_auc_ann = roc_auc_score(y_test, y_prob_ann)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_ann)

# Impresion de las métricas
print("Accuracy (ANN):", accuracy_ann)
print("Precision (ANN):", precision_ann)
print("Recall (ANN):", recall_ann)
print("F1-score (ANN):", f1_ann)
print("AUC-ROC (ANN):", roc_auc_ann)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# Curva ROC
fpr_ann, tpr_ann, thresholds_ann = roc_curve(y_test, y_prob_ann)
plt.figure()
plt.plot(fpr_ann, tpr_ann, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc_ann)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC (ANN)')
plt.legend(loc="lower right")
plt.show()

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
y_pred_ann = y_pred_ann.flatten()
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred_ann})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head(50)

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

#Varaible predictora
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre','Incorporacion de TIC en aula_Ocasionalmente',
                'Incorporacion de TIC en aula_Rara vez','Incorporacion de TIC en aula_Siempre',
                'Uso de tecnologias mejoro el aprendizaje_Sí']]

#Varaible objetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Division de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear un modelo de Árboles de Decisión
tree_model = DecisionTreeClassifier(random_state=42)

#Entrenamiento del modelo
tree_model.fit(X_train, y_train)

#Predicciones en el conjunto de prueba
y_prob_tree = tree_model.predict_proba(X_test)[:, 1]
y_pred_tree = (y_prob_tree > 0.5).astype(int)

# Calculo de métricas de evaluación
accuracy_tree = accuracy_score(y_test, y_pred_tree)
precision_tree = precision_score(y_test, y_pred_tree)
recall_tree = recall_score(y_test, y_pred_tree)
f1_tree = f1_score(y_test, y_pred_tree)
roc_auc_tree = roc_auc_score(y_test, y_prob_tree)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_tree)

# Impresion de las métricas
print("Accuracy (Decision Tree):", accuracy_tree)
print("Precision (Decision Tree):", precision_tree)
print("Recall (Decision Tree):", recall_tree)
print("F1-score (Decision Tree):", f1_tree)
print("AUC-ROC (Decision Tree):", roc_auc_tree)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# Curva ROC
fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, y_prob_tree)
plt.figure()
plt.plot(fpr_tree, tpr_tree, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc_tree)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC (Decision Tree)')
plt.legend(loc="lower right")
plt.show()

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred_tree})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head()

import joblib
# Guardar el modelo y el scaler con Joblib
joblib.dump(model, "modelo_entrenado.joblib")
joblib.dump(scaler, "scaler.joblib")

import joblib

# Guardar el modelo
joblib.dump(tree_model, 'Modelo1.pkl')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

#Varaible predictora
X = df_encoded[['Departamento',"internet en colegio_Sí", "Aula en colegio para uso de computadoras_Sí",
                "Modalidad de Clases_Clases de laboratorios",'Modalidad de Clases_Clases prácticas',
                'Incorporacion de TIC en aula_Casi siempre','Incorporacion de TIC en aula_Ocasionalmente',
                'Incorporacion de TIC en aula_Rara vez','Incorporacion de TIC en aula_Siempre',
                'Uso de tecnologias mejoro el aprendizaje_Sí',]]

#Variable objetivo
y = df_encoded["impacto de inclusion digital_Alto"]

# Division de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalamiento de las características para normalizarlas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Creacion de un modelo de red neuronal profunda (DNN)
model = keras.Sequential([
    layers.Input(shape=(X_train_scaled.shape[1],)),
    layers.Dense(128, activation='tanh'),
    layers.Dropout(0.2),
    layers.Dense(64, activation='tanh'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='tanh')
])

# Compilacion del modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenamiento del modelo
history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

#Predicciones en el conjunto de prueba
y_prob_dnn = model.predict(X_test_scaled)
y_pred_dnn = (y_prob_dnn > 0.5).astype(int)

# Calculo de métricas de evaluación
accuracy_dnn = accuracy_score(y_test, y_pred_dnn)
precision_dnn = precision_score(y_test, y_pred_dnn)
recall_dnn = recall_score(y_test, y_pred_dnn)
f1_dnn = f1_score(y_test, y_pred_dnn)
roc_auc_dnn = roc_auc_score(y_test, y_prob_dnn)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_dnn)

# Impresion de las métricas
print("Accuracy (Deep Neural Network):", accuracy_dnn)
print("Precision (Deep Neural Network):", precision_dnn)
print("Recall (Deep Neural Network):", recall_dnn)
print("F1-score (Deep Neural Network):", f1_dnn)
print("AUC-ROC (Deep Neural Network):", roc_auc_dnn)

# Matriz de confusión
print("\nMatriz de Confusión:")
print(conf_matrix)

# Curva ROC
fpr_dnn, tpr_dnn, thresholds_dnn = roc_curve(y_test, y_prob_dnn)
plt.figure()
plt.plot(fpr_dnn, tpr_dnn, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc_dnn)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC (Deep Neural Network)')
plt.legend(loc="lower right")
plt.show()

# Crear un DataFrame con las etiquetas reales (y_test) y las predicciones (y_pred)
y_pred_dnn = y_pred_dnn.flatten()
results_df = pd.DataFrame({'Real': y_test, 'Predicciones': y_pred_dnn})

# Mostrar el DataFrame con las etiquetas reales y predicciones
results_df.head()

#Caragar modelo ya entrenado.
import os
import joblib

#cargar el modelo y el scaler desde los archivos
modelo_cargado = joblib.load("modelo_entrenado.joblib")
scaler_cargado = joblib.load("scaler.joblib")

df_nuevo = pd.read_excel('/content/drive/MyDrive/dataset4.xlsx')
df_nuevo

print("Características de entrenamiento:", X_train.columns)
print("Características de df_nuevo:", df_nuevo.columns)

df_nuevo = df_nuevo[X_train.columns]

nuevos_datos_scaled = scaler_cargado.transform(df_nuevo)

# Hacer predicciones con el modelo cargado
y_prob_nuevos = modelo_cargado.predict(nuevos_datos_scaled)
y_pred_nuevos = (y_prob_nuevos > 0.5).astype(int)

df_nuevo.insert(0,'Prediccion',y_pred_nuevos,allow_duplicates=False)
df_nuevo

# Crear un diccionario de mapeo de departamentos a valores numéricos
mapeo_departamentos = {
    1: 'Pando',
    2: 'Beni',
    3: 'La Paz',
    4: 'Oruro',
    5: 'Potosí',
    6: 'Cochabamba',
    7: 'Chuquisaca',
    8: 'Tarija',
    9: 'Santa Cruz'
}

# Reemplazar los valores en la columna 'Departamento'
df_nuevo['Departamento'] = df_nuevo['Departamento'].replace(mapeo_departamentos)

df_nuevo

# prompt: exportar df_nuevo  en formato de excel

df_nuevo.to_excel('resultado_prediccion.xlsx')